{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file paths\n",
    "mushroom_path = \"../secondary_data_no_miss.csv\"\n",
    "\n",
    "# Read the data files\n",
    "mushroom_data = pd.read_csv(mushroom_path, sep = \";\")\n",
    "\n",
    "mushroom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all letters with actual value\n",
    "\n",
    "mushroom_data = mushroom_data.replace(\n",
    "    {\n",
    "    'class': {'p': 'poisonous', 'e': 'edible'},\n",
    "    'cap-shape': {'b': 'bell', 'c': 'conical', 'x': 'convex', 'f': 'flat', 's': 'sunken', 'p': 'spherical', 'o': 'others'},\n",
    "    'cap-surface': {'i': 'fibrous', 'g': 'grooves', 'y': 'scaly', 's': 'smooth', 'd': 'dry', 'h': 'shiny', 'l': 'leathery', 'k': 'silky', 't': 'sticky', 'w': 'wrinkled', 'e': 'fleshy'},\n",
    "    'cap-color': {'n': 'brown', 'b': 'buff', 'g': 'gray', 'r': 'green', 'p': 'pink', 'u': 'purple', 'e': 'red', 'w': 'white', 'y': 'yellow', 'l': 'blue', 'o': 'orange', 'k': 'black'},\n",
    "    'gill-attachment': {'a': 'adnate', 'x': 'adnexed', 'd': 'decurrent', 'e': 'free', 's': 'sinuate', 'p': 'pores', 'f': 'none', '?': 'unknown'},\n",
    "    'gill-spacing': {'c': 'close', 'd': 'distant', 'f': 'none'},\n",
    "    'gill-color': {'n': 'brown', 'b': 'buff', 'g': 'gray', 'r': 'green', 'p': 'pink', 'u': 'purple', 'e': 'red', 'w': 'white', 'y': 'yellow', 'l': 'blue', 'o': 'orange', 'k': 'black', 'f': 'none'},\n",
    "    'stem-color': {'n': 'brown', 'b': 'buff', 'g': 'gray', 'r': 'green', 'p': 'pink', 'u': 'purple', 'e': 'red', 'w': 'white', 'y': 'yellow', 'l': 'blue', 'o': 'orange', 'k': 'black', 'f': 'none'},\n",
    "    'ring-type': {'c': 'cobwebby', 'e': 'evanescent', 'r': 'flaring', 'g': 'grooved', 'l': 'large', 'p': 'pendant', 's': 'sheathing', 'z': 'zone', 'y': 'scaly', 'm': 'movable', 'f': 'none', '?': 'unknown'},\n",
    "    'habitat': {'g': 'grasses', 'l': 'leaves', 'm': 'meadows', 'p': 'paths', 'h': 'heaths', 'u': 'urban', 'w': 'waste', 'd': 'woods'},\n",
    "    'season': {'s': 'spring', 'u': 'summer', 'a': 'autumn', 'w': 'winter'}\n",
    "    })\n",
    "\n",
    "# convert t/f columns to boolean.\n",
    "mushroom_data['does-bruise-or-bleed'] = mushroom_data['does-bruise-or-bleed']=='t'\n",
    "mushroom_data['has-ring'] = mushroom_data['has-ring']=='t'\n",
    "mushroom_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run KNN on the three original quantitative data columns with standard and MinMax scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish X and y\n",
    "\n",
    "y = mushroom_data[\"class\"]\n",
    "target_names = [\"edible\", \"poisonous\"]\n",
    "\n",
    "# Need to drop all non-integer columns for KNN\n",
    "# X = mushroom_data.drop(\"class\", axis=1)\n",
    "X = mushroom_data[[\"cap-diameter\", \"stem-height\", \"stem-width\"]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Transform the training and testing data using the X_scaler and y_scaler models\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# from pickle import dump, load\n",
    "# dump(X_scaler, open('knn_scaler.pkl', 'wb'))\n",
    "\n",
    "# joblib.dump(X_scaler, 'mushroom_scaler_knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# NB: Standard scaled, 3 quantitative columns\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 30, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 13 seems to be the best choice for this dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('For a standard scaled KNN model on the three original quantitative columns: k=17 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "import joblib\n",
    "# import pickle\n",
    "# from pickle import dump, load\n",
    "# pickle.dump(knn, open(\"knn_standard_three.pkl\", \"wb\"))\n",
    "\n",
    "# # Save the model as a pickle in a file\n",
    "# joblib.dump(knn, 'knn_standard_three.pkl')\n",
    "\n",
    "# # Load the model from the file\n",
    "# knn_from_joblib = joblib.load('knn_standard_three.pkl')\n",
    "\n",
    "# # Use the loaded model to make predictions\n",
    "# knn_from_joblib.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Transform the training and testing data using the X_scaler and y_scaler models\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Loop through different k values to see which has the highest accuracy\n",
    "# NB: Standard scaled, 3 quantitative columns\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 30, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 30, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 30, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 13 seems to be the best choice for this dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('For a min/max scaled KNN model on the three original quantitative columns: k=17 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model as a pickle in a file\n",
    "# joblib.dump(knn, 'knn_minmax_three.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dummy columns for categorical data and run KNN (standard, MinMax) on all data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mushroom_category = pd.get_dummies(data=mushroom_data, columns=[\n",
    "                                                'cap-surface',\n",
    "                                                'cap-color',\n",
    "                                                'does-bruise-or-bleed',\n",
    "                                                'gill-attachment',\n",
    "                                                'gill-spacing',\n",
    "                                                'gill-color',\n",
    "                                                'cap-shape',\n",
    "                                                'stem-color',\n",
    "                                                'has-ring',\n",
    "                                                'ring-type',\n",
    "                                                'habitat',\n",
    "                                                'season'])\n",
    "\n",
    "# mushroom_category.to_csv(\"mushroom_category.csv\", index=False)\n",
    "\n",
    "mushroom_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mushroom_category[\"class\"]\n",
    "target_names = [\"edible\", \"poisonous\"]\n",
    "\n",
    "# X = mushroom_data.drop(\"class\", axis=1)\n",
    "X = mushroom_category.drop(\"class\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler with get_dummies columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler model and fit it to the training data\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler and y_scaler models\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 10, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 10, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 10, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 3 seems to be the best choice for this dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('For a standard scaled KNN model on all columns: k=3 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model as a pickle in a file\n",
    "# joblib.dump(knn, 'knn_standard_all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScaler with get_dummies columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a StandardScaler model and fit it to the training data\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler and y_scaler models\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 10, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 10, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 10, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 2 seems to be the best choice for this dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('For a MinMax scaled KNN model on all columns: k=2 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial stab at neural network with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a neural network\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mushroom_category.drop(\"class\", axis=1)\n",
    "y = mushroom_category[\"class\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# joblib.dump(X_scaler, 'mushroom_scaler.pkl')\n",
    "\n",
    "# from pickle import dump\n",
    "# dump(X_scaler, open('mush_nn_scale.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create a normal neural network with 2 inputs, 6 hidden nodes, and 2 outputs\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Make a sequential model\n",
    "model = Sequential()\n",
    "# Add the first hidden layer with 6 nodes\n",
    "model.add(Dense(units=6, activation='relu', input_dim=92))\n",
    "# Add the output layer with 2 outputs\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# model.save(\"mushroom_trained.h5\")\n",
    "\n",
    "# import tensorflow as tf\n",
    "# mushroom_model = tf.keras.models.load_model('mushroom_trained.h5')\n",
    "\n",
    "# mushroom_model.predict(new_data)\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# mushroom_model = 'mushroom_model.sav'\n",
    "# pickle.dump(model, open(mushroom_model, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "mushroom_model = load_model(\"mushroom_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = mushroom_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_test_scaled[1], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "print(f\"Predicted class: {model.predict_classes(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
